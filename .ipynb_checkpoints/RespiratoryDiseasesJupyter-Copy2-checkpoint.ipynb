{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2083b0",
   "metadata": {},
   "source": [
    "**Predicting Respiratory Diseases by the Patientâ€™s Breathing Sounds**\n",
    "\n",
    "Kaarel Tamuri<br>\n",
    "Stina-Marie Maripuu\n",
    "\n",
    "Set within the healthcare industry, this project focuses on supporting the diagnostic process for respiratory diseases. It aims to harness the potential of machine learning to analyze breathing sounds, to help cure patients more effectively and reliably.\n",
    "\n",
    "We are using CNN (Convolutional Neural Network), which is a network architecture for deep learning that learns directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBARIES\n",
    "!pip3 install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db17943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import resampy\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ecb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All PATHS TO DATA\n",
    "path_files = \"archive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/\"\n",
    "path_diagnose = \"archive/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.wav filenames\n",
    "wav_files = []\n",
    "for file in os.listdir(path_files):\n",
    "    if file.endswith(\".wav\"):\n",
    "        wav_files.append(file)\n",
    "\n",
    "\n",
    "#patient_diagnosis.csv\n",
    "diagnose = pd.read_csv(path_diagnose, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all file paths\n",
    "filepaths = []\n",
    "for i in wav_files:\n",
    "    path = path_files+i\n",
    "    filepaths.append(path)\n",
    "\n",
    "\n",
    "#Find diagnose for every file\n",
    "\n",
    "file_patient =[]\n",
    "for i in wav_files:\n",
    "    pn = int (i[:3])\n",
    "    file_patient.append(pn)\n",
    "\n",
    "file_patient = np.array(file_patient)\n",
    "\n",
    "labels = []\n",
    "for i in file_patient:\n",
    "    row = diagnose[diagnose[0] == i]\n",
    "    labels.append(row[1].values[0])\n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(labels, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(unique_elements, counts_elements, color='skyblue')\n",
    "\n",
    "# Adding the count labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom', ha='center')\n",
    "\n",
    "plt.xlabel('Illness')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Each Illness Based On Audio Files Before Data Balancing')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, noise_level=0.005):\n",
    "    noise = np.random.randn(len(data))\n",
    "    return data + noise_level * noise\n",
    "\n",
    "def time_shift(data, sampling_rate, shift_max=0.2):\n",
    "    shift_amount = int(sampling_rate * shift_max)\n",
    "    shift = np.random.randint(-shift_amount, shift_amount)\n",
    "    return np.roll(data, shift)\n",
    "\n",
    "def change_pitch(audio, sample_rate, n_steps=2.0, bins_per_octave=12, res_type='soxr_hq', scale=False):\n",
    "    return librosa.effects.pitch_shift(y=audio, sr=sample_rate, n_steps=n_steps, \n",
    "                                       bins_per_octave=bins_per_octave, res_type=res_type, scale=scale)\n",
    "\n",
    "def change_speed(audio, speed_factor=1.2):\n",
    "    return librosa.effects.time_stretch(y=audio, rate=speed_factor)\n",
    "\n",
    "\n",
    "\n",
    "def data_augmentation(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    augmented_audio = [\n",
    "        add_noise(audio),\n",
    "        time_shift(audio, sample_rate),\n",
    "        change_pitch(audio, sample_rate),\n",
    "        change_speed(audio),\n",
    "    ]\n",
    "    return augmented_audio, sample_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioLen(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "    duration = len(audio) / sample_rate\n",
    "    return duration\n",
    "\n",
    "durations = []\n",
    "for i in filepaths:\n",
    "    durations.append(audioLen(i))\n",
    "    \n",
    "\n",
    "max_dur = max(durations)\n",
    "min_dur = min(durations)\n",
    "mean_dur = np.mean(durations)\n",
    "median_dur = np.median(durations)\n",
    "percentile_90 = np.percentile(durations, 90)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Maximum: {max_dur}\")\n",
    "print(f\"Minimum: {min_dur}\")\n",
    "print(f\"Mean: {mean_dur}\")\n",
    "print(f\"Median: {median_dur}\")\n",
    "print(f\"90th Percentile: {percentile_90}\")\n",
    "\n",
    "plt.hist(durations, bins='auto', color='blue', alpha=0.7, rwidth=0.85)\n",
    "plt.title('Audiofile Durations')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa03841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I take 90th Percentile to cover as much as possible, but to not be as slow\n",
    "durLen = 20\n",
    "paddingLen = int(np.ceil(durLen*22050/512))\n",
    "\n",
    "\n",
    "def extract(file_path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast', duration=durLen) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = paddingLen - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(file_path, e)\n",
    "        return None \n",
    "\n",
    "    return mfccs\n",
    "\n",
    "\n",
    "def extract_features_from_augmented_audio(file_path):\n",
    "    augmented_audios, sample_rate = data_augmentation(file_path)\n",
    "    augmented_features = []  # Initialize an empty list to store features\n",
    "    for aug_audio in augmented_audios:\n",
    "        mfccs = librosa.feature.mfcc(y=aug_audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = paddingLen - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        augmented_features.append(mfccs)\n",
    "    return augmented_features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsNew = []\n",
    "featuresNew = []\n",
    "\n",
    "# Use tqdm for the progress bar\n",
    "for file_path, label in tqdm(zip(filepaths, labels), total=len(filepaths), desc=\"Processing files\"):\n",
    "    \n",
    "    #augment data\n",
    "    if label not in [\"COPD\", \"LRTI\", \"Asthma\"]:\n",
    "        augmented_audios, sample_rate = data_augmentation(file_path)\n",
    "        for aug_audio in augmented_audios:\n",
    "            mfccs = librosa.feature.mfcc(y=aug_audio, sr=sample_rate, n_mfcc=40)\n",
    "            pad_width = paddingLen - mfccs.shape[1]\n",
    "            mfccs_padded = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "            featuresNew.append(mfccs_padded)\n",
    "            labelsNew.append(label)\n",
    "\n",
    "\n",
    "    mfccs = extract(file_path)\n",
    "    featuresNew.append(mfccs)\n",
    "    labelsNew.append(label)\n",
    "\n",
    "featuresNew = np.array(featuresNew)\n",
    "labelsNew = np.array(labelsNew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dafaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = featuresNew\n",
    "labels = labelsNew\n",
    "\n",
    "#We can not train a model, when there are too few samples. \n",
    "#Therefore, we do not include Asthma and LTRI.\n",
    "features1 = np.delete(features, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0) \n",
    "labels1 = np.delete(labels, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)\n",
    "\n",
    "# features per ilness\n",
    "unique_elements, counts_elements = np.unique(labels1, return_counts=True)\n",
    "\n",
    "for i in range(len(unique_elements)):\n",
    "    print(\"Ilness: \"+unique_elements[i]+\"; Count: \"+str(counts_elements[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ecf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#One hot\n",
    "le = LabelEncoder()\n",
    "labelDummies = le.fit_transform(labels1)  # Change Labels string to int\n",
    "labelDummiesList = to_categorical(labelDummies)\n",
    "# Make list by using labelDummies\n",
    "\n",
    "\n",
    "features = np.reshape(features1, (*features1.shape, 1))\n",
    "#ERROR\n",
    "# Make Train/Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features1, labelDummiesList, stratify=labelDummiesList, test_size=0.2, random_state=1)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "\n",
    "# Reshape the features back after SMOTE\n",
    "X_train_smote = X_train_smote.reshape(X_train_smote.shape[0], features1.shape[1], features1.shape[2], 1)\n",
    "len(labelDummiesList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19aa456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels back to label encoding\n",
    "y_train_smote_labels = np.argmax(y_train_smote, axis=1)\n",
    "\n",
    "# Count the occurrences of each class\n",
    "unique_classes, counts_classes = np.unique(y_train_smote_labels, return_counts=True)\n",
    "\n",
    "# Map the integer labels back to the original class names\n",
    "class_names = le.inverse_transform(unique_classes)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(class_names, counts_classes, color='skyblue')\n",
    "\n",
    "# Adding count labels on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom', ha='center')\n",
    "\n",
    "plt.xlabel('Illness')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Each Illness Based On Audio Files After Data Balancing')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46003246",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 40 #MFCC number\n",
    "columns = paddingLen #frames\n",
    "channels = 1\n",
    "\n",
    "num_labels = labelDummiesList.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size,\n",
    "                 input_shape=(rows, columns, channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2413051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy', metrics.Recall()], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "num_epochs = 200\n",
    "num_batch_size = 128\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote, batch_size=num_batch_size, epochs=num_epochs,\n",
    "          validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "train_loss, train_accuracy, train_recall = model.evaluate(X_train_smote, y_train_smote, verbose=1)\n",
    "test_loss, test_accuracy, test_recall = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Training:\")\n",
    "print(\"\\tAccuracy:\", train_accuracy)\n",
    "print(\"\\tRecall:\", train_recall)\n",
    "\n",
    "\n",
    "print(\"Testing:\")\n",
    "print(\"\\tAccuracy:\", test_accuracy)\n",
    "print(\"\\tRecall:\", test_recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the bar chart\n",
    "metrics = ['Accuracy', 'Recall']\n",
    "train_values = [train_accuracy, train_recall]\n",
    "test_values = [test_accuracy, test_recall]\n",
    "\n",
    "x = np.arange(len(metrics))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_bars = plt.bar(x - width/2, train_values, width, label='Train', color='blue', alpha=0.7)\n",
    "test_bars = plt.bar(x + width/2, test_values, width, label='Test', color='green', alpha=0.7)\n",
    "\n",
    "# Adding labels to the bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom', ha='center')\n",
    "\n",
    "add_labels(train_bars)\n",
    "add_labels(test_bars)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Model Performance on Train vs Test Set')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "predClass = np.argmax(predictions, axis=1)\n",
    "\n",
    "realClass = np.argmax(y_test, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a55c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(len(unique_classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd236ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "for i in range(len(c_names)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for {c_names[i]}')\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.title('ROC')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28534f13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(realClass, predClass, target_names=c_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
